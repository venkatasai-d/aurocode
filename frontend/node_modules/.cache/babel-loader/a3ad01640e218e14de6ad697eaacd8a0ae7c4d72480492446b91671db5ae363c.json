{"ast":null,"code":"var _jsxFileName = \"F:\\\\Kode\\\\Projects\\\\CGP_InterviewBot\\\\frontend\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { askOllama, storeInterview } from \"./api\"; // Import the API methods\n// import \"./App.css\"; // Import CSS for styling\n\n// function App() {\n//   const [name, setName] = useState(\"\");\n//   const [questions, setQuestions] = useState([]);\n//   const [currentQuestion, setCurrentQuestion] = useState(\"\");\n//   const [currentAnswer, setCurrentAnswer] = useState(\"\");\n//   const { transcript, resetTranscript, listening } = useSpeechRecognition(); // Include listening state\n//   const [llamaResponse, setLlamaResponse] = useState(\"\");\n\n//   let listenFlag = false;\n\n//   // Function to fetch a question from the LLM (LLama) backend\n//   const fetchOllamaQuestion = async () => {\n//     try {\n//       const response = await askOllama(\n//         \"Ask me a short interview question in Java\"\n//       );\n//       setCurrentQuestion(response.data.question);\n//       setQuestions([...questions, response.data.question]);\n//       setLlamaResponse(response.data.question); // Update to Ollama response\n//     } catch (error) {\n//       console.error(\"Error fetching question from Ollama:\", error);\n//       setLlamaResponse(\"Error: Unable to fetch question from Ollama\");\n//     }\n//   };\n\n//   const toggleListening = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening();\n//       setCurrentAnswer(transcript); // Set the current transcript as the answer\n//       resetTranscript(); // Reset the transcript after stopping\n//     } else {\n//       SpeechRecognition.startListening({ continuous: true });\n//     }\n//   };\n\n//   // Function to submit the interview responses to the backend\n//   const handleSubmit = async () => {\n//     const interview = {\n//       interviewee_name: name,\n//       responses: questions.map((q) => ({ question: q, answer: currentAnswer })),\n//     };\n//     console.log(\"Submitting interview data:\", interview);\n//     try {\n//       await storeInterview(interview); // This will call the backend and store the interview\n//       alert(\"Interview submitted!\");\n//     } catch (error) {\n//       console.error(\"Error submitting the interview:\", error);\n//     }\n//   };\n\n//   return (\n//     <div className=\"App\">\n//       <h1>Interview Bot</h1>\n\n//       <input\n//         type=\"text\"\n//         placeholder=\"Enter your name\"\n//         value={name}\n//         onChange={(e) => setName(e.target.value)}\n//       />\n\n//       <button onClick={fetchOllamaQuestion}>Ask Ollama</button>\n//       <br></br>\n\n//       {llamaResponse && (\n//         <div>\n//           <h3>LLama Response:</h3>\n//           <p>{llamaResponse}</p> {/* Display the response here */}\n//         </div>\n//       )}\n\n//       {/* Toggle listening button */}\n//       <button onClick={toggleListening}>\n//         {listening ? \"Stop Listening\" : \"Start Answering\"}\n//       </button>\n\n//       <p>\n//         <strong>Your Answer:</strong> {transcript}\n//       </p>\n\n//       <button onClick={handleSubmit}>Submit Interview</button>\n//     </div>\n//   );\n// }\n\n// export default App;\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\nimport React, { useState, useRef } from \"react\";\nimport { askOllama, storeInterview } from \"./api\"; // Import the API methods\nimport \"./App.css\"; // Import CSS for styling\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [name, setName] = useState(\"\");\n  const [questions, setQuestions] = useState([]);\n  const [currentQuestion, setCurrentQuestion] = useState(\"\");\n  const [transcript, setTranscript] = useState(\"\"); // To store the transcript in real-time\n  const [llamaResponse, setLlamaResponse] = useState(\"\");\n  const [recording, setRecording] = useState(false); // Track recording state\n  const mediaRecorderRef = useRef(null);\n  const audioChunksRef = useRef([]);\n  const socketRef = useRef(null); // Ref for WebSocket connection\n\n  // Function to fetch a question from the LLM (Ollama) backend\n  const fetchOllamaQuestion = async () => {\n    try {\n      const response = await askOllama(\"Ask me a question about programming\");\n      setCurrentQuestion(response.data.question);\n      setQuestions([...questions, response.data.question]);\n      setLlamaResponse(response.data.question);\n    } catch (error) {\n      console.error(\"Error fetching question from Ollama:\", error);\n      setLlamaResponse(\"Error: Unable to fetch question from Ollama\");\n    }\n  };\n\n  // Function to handle recording start/stop\n  const toggleRecording = () => {\n    if (recording) {\n      stopRecording();\n    } else {\n      startRecording();\n    }\n  };\n  const startRecording = () => {\n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n      navigator.mediaDevices.getUserMedia({\n        audio: true\n      }).then(stream => {\n        const mediaRecorder = new MediaRecorder(stream);\n        mediaRecorderRef.current = mediaRecorder;\n        audioChunksRef.current = [];\n\n        // Set up WebSocket connection to backend\n        socketRef.current = new WebSocket(\"ws://localhost:8000/ws/live-stt\");\n        socketRef.current.onopen = () => {\n          console.log(\"WebSocket connection opened\");\n        };\n        socketRef.current.onmessage = event => {\n          const data = JSON.parse(event.data);\n          if (data.partial) {\n            setTranscript(data.partial); // Update the transcript in real-time\n          } else if (data.text) {\n            setTranscript(data.text); // Set final transcript when complete\n          }\n        };\n        mediaRecorder.ondataavailable = event => {\n          audioChunksRef.current.push(event.data);\n          if (socketRef.current.readyState === WebSocket.OPEN) {\n            socketRef.current.send(event.data); // Send audio chunks to WebSocket\n          }\n        };\n        mediaRecorder.start(200); // Send audio chunks every 200ms\n        setRecording(true);\n      }).catch(error => {\n        console.error(\"Error accessing microphone:\", error);\n      });\n    }\n  };\n  const stopRecording = () => {\n    const mediaRecorder = mediaRecorderRef.current;\n    if (mediaRecorder) {\n      mediaRecorder.stop();\n      mediaRecorder.onstop = () => {\n        if (socketRef.current) {\n          socketRef.current.close(); // Close WebSocket connection\n        }\n        setRecording(false);\n      };\n    }\n  };\n\n  // Function to submit the interview responses to the backend\n  const handleSubmit = async () => {\n    const interview = {\n      interviewee_name: name,\n      responses: questions.map(q => ({\n        question: q,\n        answer: transcript\n      }))\n    };\n    console.log(\"Submitting interview data:\", interview);\n    try {\n      await storeInterview(interview); // This will call the backend and store the interview\n      alert(\"Interview submitted!\");\n    } catch (error) {\n      console.error(\"Error submitting the interview:\", error);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Interview Bot\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 204,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"input\", {\n      type: \"text\",\n      placeholder: \"Enter your name\",\n      value: name,\n      onChange: e => setName(e.target.value)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 206,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: fetchOllamaQuestion,\n      children: \"Ask Ollama\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 213,\n      columnNumber: 7\n    }, this), llamaResponse && /*#__PURE__*/_jsxDEV(\"div\", {\n      children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n        children: \"Ollama Response:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 217,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: llamaResponse\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 218,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 216,\n      columnNumber: 9\n    }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 225,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: toggleRecording,\n      children: recording ? \"Stop Recording\" : \"Start Answering\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 227,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n      children: [/*#__PURE__*/_jsxDEV(\"strong\", {\n        children: \"Your Answer (Real-Time Transcript):\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 232,\n        columnNumber: 9\n      }, this), \" \", transcript]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 231,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handleSubmit,\n      children: \"Submit Interview\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 235,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 203,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"f1zuxrxhDX7kJpt865iaPjJ0+jY=\");\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","useRef","askOllama","storeInterview","jsxDEV","_jsxDEV","App","_s","name","setName","questions","setQuestions","currentQuestion","setCurrentQuestion","transcript","setTranscript","llamaResponse","setLlamaResponse","recording","setRecording","mediaRecorderRef","audioChunksRef","socketRef","fetchOllamaQuestion","response","data","question","error","console","toggleRecording","stopRecording","startRecording","navigator","mediaDevices","getUserMedia","audio","then","stream","mediaRecorder","MediaRecorder","current","WebSocket","onopen","log","onmessage","event","JSON","parse","partial","text","ondataavailable","push","readyState","OPEN","send","start","catch","stop","onstop","close","handleSubmit","interview","interviewee_name","responses","map","q","answer","alert","className","children","fileName","_jsxFileName","lineNumber","columnNumber","type","placeholder","value","onChange","e","target","onClick","_c","$RefreshReg$"],"sources":["F:/Kode/Projects/CGP_InterviewBot/frontend/src/App.js"],"sourcesContent":["// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { askOllama, storeInterview } from \"./api\"; // Import the API methods\n// import \"./App.css\"; // Import CSS for styling\n\n// function App() {\n//   const [name, setName] = useState(\"\");\n//   const [questions, setQuestions] = useState([]);\n//   const [currentQuestion, setCurrentQuestion] = useState(\"\");\n//   const [currentAnswer, setCurrentAnswer] = useState(\"\");\n//   const { transcript, resetTranscript, listening } = useSpeechRecognition(); // Include listening state\n//   const [llamaResponse, setLlamaResponse] = useState(\"\");\n\n//   let listenFlag = false;\n\n//   // Function to fetch a question from the LLM (LLama) backend\n//   const fetchOllamaQuestion = async () => {\n//     try {\n//       const response = await askOllama(\n//         \"Ask me a short interview question in Java\"\n//       );\n//       setCurrentQuestion(response.data.question);\n//       setQuestions([...questions, response.data.question]);\n//       setLlamaResponse(response.data.question); // Update to Ollama response\n//     } catch (error) {\n//       console.error(\"Error fetching question from Ollama:\", error);\n//       setLlamaResponse(\"Error: Unable to fetch question from Ollama\");\n//     }\n//   };\n\n//   const toggleListening = () => {\n//     if (listening) {\n//       SpeechRecognition.stopListening();\n//       setCurrentAnswer(transcript); // Set the current transcript as the answer\n//       resetTranscript(); // Reset the transcript after stopping\n//     } else {\n//       SpeechRecognition.startListening({ continuous: true });\n//     }\n//   };\n\n//   // Function to submit the interview responses to the backend\n//   const handleSubmit = async () => {\n//     const interview = {\n//       interviewee_name: name,\n//       responses: questions.map((q) => ({ question: q, answer: currentAnswer })),\n//     };\n//     console.log(\"Submitting interview data:\", interview);\n//     try {\n//       await storeInterview(interview); // This will call the backend and store the interview\n//       alert(\"Interview submitted!\");\n//     } catch (error) {\n//       console.error(\"Error submitting the interview:\", error);\n//     }\n//   };\n\n//   return (\n//     <div className=\"App\">\n//       <h1>Interview Bot</h1>\n\n//       <input\n//         type=\"text\"\n//         placeholder=\"Enter your name\"\n//         value={name}\n//         onChange={(e) => setName(e.target.value)}\n//       />\n\n//       <button onClick={fetchOllamaQuestion}>Ask Ollama</button>\n//       <br></br>\n\n//       {llamaResponse && (\n//         <div>\n//           <h3>LLama Response:</h3>\n//           <p>{llamaResponse}</p> {/* Display the response here */}\n//         </div>\n//       )}\n\n//       {/* Toggle listening button */}\n//       <button onClick={toggleListening}>\n//         {listening ? \"Stop Listening\" : \"Start Answering\"}\n//       </button>\n\n//       <p>\n//         <strong>Your Answer:</strong> {transcript}\n//       </p>\n\n//       <button onClick={handleSubmit}>Submit Interview</button>\n//     </div>\n//   );\n// }\n\n// export default App;\n/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n\nimport React, { useState, useRef } from \"react\";\nimport { askOllama, storeInterview } from \"./api\"; // Import the API methods\nimport \"./App.css\"; // Import CSS for styling\n\nfunction App() {\n  const [name, setName] = useState(\"\");\n  const [questions, setQuestions] = useState([]);\n  const [currentQuestion, setCurrentQuestion] = useState(\"\");\n  const [transcript, setTranscript] = useState(\"\"); // To store the transcript in real-time\n  const [llamaResponse, setLlamaResponse] = useState(\"\");\n  const [recording, setRecording] = useState(false); // Track recording state\n  const mediaRecorderRef = useRef(null);\n  const audioChunksRef = useRef([]);\n  const socketRef = useRef(null); // Ref for WebSocket connection\n\n  // Function to fetch a question from the LLM (Ollama) backend\n  const fetchOllamaQuestion = async () => {\n    try {\n      const response = await askOllama(\"Ask me a question about programming\");\n      setCurrentQuestion(response.data.question);\n      setQuestions([...questions, response.data.question]);\n      setLlamaResponse(response.data.question);\n    } catch (error) {\n      console.error(\"Error fetching question from Ollama:\", error);\n      setLlamaResponse(\"Error: Unable to fetch question from Ollama\");\n    }\n  };\n\n  // Function to handle recording start/stop\n  const toggleRecording = () => {\n    if (recording) {\n      stopRecording();\n    } else {\n      startRecording();\n    }\n  };\n\n  const startRecording = () => {\n    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n      navigator.mediaDevices\n        .getUserMedia({ audio: true })\n        .then((stream) => {\n          const mediaRecorder = new MediaRecorder(stream);\n          mediaRecorderRef.current = mediaRecorder;\n          audioChunksRef.current = [];\n\n          // Set up WebSocket connection to backend\n          socketRef.current = new WebSocket(\"ws://localhost:8000/ws/live-stt\");\n\n          socketRef.current.onopen = () => {\n            console.log(\"WebSocket connection opened\");\n          };\n\n          socketRef.current.onmessage = (event) => {\n            const data = JSON.parse(event.data);\n            if (data.partial) {\n              setTranscript(data.partial); // Update the transcript in real-time\n            } else if (data.text) {\n              setTranscript(data.text); // Set final transcript when complete\n            }\n          };\n\n          mediaRecorder.ondataavailable = (event) => {\n            audioChunksRef.current.push(event.data);\n            if (socketRef.current.readyState === WebSocket.OPEN) {\n              socketRef.current.send(event.data); // Send audio chunks to WebSocket\n            }\n          };\n\n          mediaRecorder.start(200); // Send audio chunks every 200ms\n          setRecording(true);\n        })\n        .catch((error) => {\n          console.error(\"Error accessing microphone:\", error);\n        });\n    }\n  };\n\n  const stopRecording = () => {\n    const mediaRecorder = mediaRecorderRef.current;\n    if (mediaRecorder) {\n      mediaRecorder.stop();\n      mediaRecorder.onstop = () => {\n        if (socketRef.current) {\n          socketRef.current.close(); // Close WebSocket connection\n        }\n        setRecording(false);\n      };\n    }\n  };\n\n  // Function to submit the interview responses to the backend\n  const handleSubmit = async () => {\n    const interview = {\n      interviewee_name: name,\n      responses: questions.map((q) => ({ question: q, answer: transcript })),\n    };\n    console.log(\"Submitting interview data:\", interview);\n    try {\n      await storeInterview(interview); // This will call the backend and store the interview\n      alert(\"Interview submitted!\");\n    } catch (error) {\n      console.error(\"Error submitting the interview:\", error);\n    }\n  };\n\n  return (\n    <div className=\"App\">\n      <h1>Interview Bot</h1>\n\n      <input\n        type=\"text\"\n        placeholder=\"Enter your name\"\n        value={name}\n        onChange={(e) => setName(e.target.value)}\n      />\n\n      <button onClick={fetchOllamaQuestion}>Ask Ollama</button>\n\n      {llamaResponse && (\n        <div>\n          <h3>Ollama Response:</h3>\n          <p>{llamaResponse}</p>\n        </div>\n      )}\n\n      {/* <p>\n        <strong>Question:</strong> {currentQuestion}\n      </p> */}\n      <br></br>\n      {/* Toggle recording button */}\n      <button onClick={toggleRecording}>\n        {recording ? \"Stop Recording\" : \"Start Answering\"}\n      </button>\n\n      <p>\n        <strong>Your Answer (Real-Time Transcript):</strong> {transcript}\n      </p>\n\n      <button onClick={handleSubmit}>Submit Interview</button>\n    </div>\n  );\n}\n\nexport default App;\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AAC/C,SAASC,SAAS,EAAEC,cAAc,QAAQ,OAAO,CAAC,CAAC;AACnD,OAAO,WAAW,CAAC,CAAC;AAAA,SAAAC,MAAA,IAAAC,OAAA;AAEpB,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACb,MAAM,CAACC,IAAI,EAAEC,OAAO,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EACpC,MAAM,CAACU,SAAS,EAAEC,YAAY,CAAC,GAAGX,QAAQ,CAAC,EAAE,CAAC;EAC9C,MAAM,CAACY,eAAe,EAAEC,kBAAkB,CAAC,GAAGb,QAAQ,CAAC,EAAE,CAAC;EAC1D,MAAM,CAACc,UAAU,EAAEC,aAAa,CAAC,GAAGf,QAAQ,CAAC,EAAE,CAAC,CAAC,CAAC;EAClD,MAAM,CAACgB,aAAa,EAAEC,gBAAgB,CAAC,GAAGjB,QAAQ,CAAC,EAAE,CAAC;EACtD,MAAM,CAACkB,SAAS,EAAEC,YAAY,CAAC,GAAGnB,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;EACnD,MAAMoB,gBAAgB,GAAGnB,MAAM,CAAC,IAAI,CAAC;EACrC,MAAMoB,cAAc,GAAGpB,MAAM,CAAC,EAAE,CAAC;EACjC,MAAMqB,SAAS,GAAGrB,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC;;EAEhC;EACA,MAAMsB,mBAAmB,GAAG,MAAAA,CAAA,KAAY;IACtC,IAAI;MACF,MAAMC,QAAQ,GAAG,MAAMtB,SAAS,CAAC,qCAAqC,CAAC;MACvEW,kBAAkB,CAACW,QAAQ,CAACC,IAAI,CAACC,QAAQ,CAAC;MAC1Cf,YAAY,CAAC,CAAC,GAAGD,SAAS,EAAEc,QAAQ,CAACC,IAAI,CAACC,QAAQ,CAAC,CAAC;MACpDT,gBAAgB,CAACO,QAAQ,CAACC,IAAI,CAACC,QAAQ,CAAC;IAC1C,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;MAC5DV,gBAAgB,CAAC,6CAA6C,CAAC;IACjE;EACF,CAAC;;EAED;EACA,MAAMY,eAAe,GAAGA,CAAA,KAAM;IAC5B,IAAIX,SAAS,EAAE;MACbY,aAAa,CAAC,CAAC;IACjB,CAAC,MAAM;MACLC,cAAc,CAAC,CAAC;IAClB;EACF,CAAC;EAED,MAAMA,cAAc,GAAGA,CAAA,KAAM;IAC3B,IAAIC,SAAS,CAACC,YAAY,IAAID,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;MACjEF,SAAS,CAACC,YAAY,CACnBC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC,CAC7BC,IAAI,CAAEC,MAAM,IAAK;QAChB,MAAMC,aAAa,GAAG,IAAIC,aAAa,CAACF,MAAM,CAAC;QAC/CjB,gBAAgB,CAACoB,OAAO,GAAGF,aAAa;QACxCjB,cAAc,CAACmB,OAAO,GAAG,EAAE;;QAE3B;QACAlB,SAAS,CAACkB,OAAO,GAAG,IAAIC,SAAS,CAAC,iCAAiC,CAAC;QAEpEnB,SAAS,CAACkB,OAAO,CAACE,MAAM,GAAG,MAAM;UAC/Bd,OAAO,CAACe,GAAG,CAAC,6BAA6B,CAAC;QAC5C,CAAC;QAEDrB,SAAS,CAACkB,OAAO,CAACI,SAAS,GAAIC,KAAK,IAAK;UACvC,MAAMpB,IAAI,GAAGqB,IAAI,CAACC,KAAK,CAACF,KAAK,CAACpB,IAAI,CAAC;UACnC,IAAIA,IAAI,CAACuB,OAAO,EAAE;YAChBjC,aAAa,CAACU,IAAI,CAACuB,OAAO,CAAC,CAAC,CAAC;UAC/B,CAAC,MAAM,IAAIvB,IAAI,CAACwB,IAAI,EAAE;YACpBlC,aAAa,CAACU,IAAI,CAACwB,IAAI,CAAC,CAAC,CAAC;UAC5B;QACF,CAAC;QAEDX,aAAa,CAACY,eAAe,GAAIL,KAAK,IAAK;UACzCxB,cAAc,CAACmB,OAAO,CAACW,IAAI,CAACN,KAAK,CAACpB,IAAI,CAAC;UACvC,IAAIH,SAAS,CAACkB,OAAO,CAACY,UAAU,KAAKX,SAAS,CAACY,IAAI,EAAE;YACnD/B,SAAS,CAACkB,OAAO,CAACc,IAAI,CAACT,KAAK,CAACpB,IAAI,CAAC,CAAC,CAAC;UACtC;QACF,CAAC;QAEDa,aAAa,CAACiB,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;QAC1BpC,YAAY,CAAC,IAAI,CAAC;MACpB,CAAC,CAAC,CACDqC,KAAK,CAAE7B,KAAK,IAAK;QAChBC,OAAO,CAACD,KAAK,CAAC,6BAA6B,EAAEA,KAAK,CAAC;MACrD,CAAC,CAAC;IACN;EACF,CAAC;EAED,MAAMG,aAAa,GAAGA,CAAA,KAAM;IAC1B,MAAMQ,aAAa,GAAGlB,gBAAgB,CAACoB,OAAO;IAC9C,IAAIF,aAAa,EAAE;MACjBA,aAAa,CAACmB,IAAI,CAAC,CAAC;MACpBnB,aAAa,CAACoB,MAAM,GAAG,MAAM;QAC3B,IAAIpC,SAAS,CAACkB,OAAO,EAAE;UACrBlB,SAAS,CAACkB,OAAO,CAACmB,KAAK,CAAC,CAAC,CAAC,CAAC;QAC7B;QACAxC,YAAY,CAAC,KAAK,CAAC;MACrB,CAAC;IACH;EACF,CAAC;;EAED;EACA,MAAMyC,YAAY,GAAG,MAAAA,CAAA,KAAY;IAC/B,MAAMC,SAAS,GAAG;MAChBC,gBAAgB,EAAEtD,IAAI;MACtBuD,SAAS,EAAErD,SAAS,CAACsD,GAAG,CAAEC,CAAC,KAAM;QAAEvC,QAAQ,EAAEuC,CAAC;QAAEC,MAAM,EAAEpD;MAAW,CAAC,CAAC;IACvE,CAAC;IACDc,OAAO,CAACe,GAAG,CAAC,4BAA4B,EAAEkB,SAAS,CAAC;IACpD,IAAI;MACF,MAAM1D,cAAc,CAAC0D,SAAS,CAAC,CAAC,CAAC;MACjCM,KAAK,CAAC,sBAAsB,CAAC;IAC/B,CAAC,CAAC,OAAOxC,KAAK,EAAE;MACdC,OAAO,CAACD,KAAK,CAAC,iCAAiC,EAAEA,KAAK,CAAC;IACzD;EACF,CAAC;EAED,oBACEtB,OAAA;IAAK+D,SAAS,EAAC,KAAK;IAAAC,QAAA,gBAClBhE,OAAA;MAAAgE,QAAA,EAAI;IAAa;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAEtBpE,OAAA;MACEqE,IAAI,EAAC,MAAM;MACXC,WAAW,EAAC,iBAAiB;MAC7BC,KAAK,EAAEpE,IAAK;MACZqE,QAAQ,EAAGC,CAAC,IAAKrE,OAAO,CAACqE,CAAC,CAACC,MAAM,CAACH,KAAK;IAAE;MAAAN,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC1C,CAAC,eAEFpE,OAAA;MAAQ2E,OAAO,EAAEzD,mBAAoB;MAAA8C,QAAA,EAAC;IAAU;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,EAExDzD,aAAa,iBACZX,OAAA;MAAAgE,QAAA,gBACEhE,OAAA;QAAAgE,QAAA,EAAI;MAAgB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC,eACzBpE,OAAA;QAAAgE,QAAA,EAAIrD;MAAa;QAAAsD,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACnB,CACN,eAKDpE,OAAA;MAAAiE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eAETpE,OAAA;MAAQ2E,OAAO,EAAEnD,eAAgB;MAAAwC,QAAA,EAC9BnD,SAAS,GAAG,gBAAgB,GAAG;IAAiB;MAAAoD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC3C,CAAC,eAETpE,OAAA;MAAAgE,QAAA,gBACEhE,OAAA;QAAAgE,QAAA,EAAQ;MAAmC;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,KAAC,EAAC3D,UAAU;IAAA;MAAAwD,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC/D,CAAC,eAEJpE,OAAA;MAAQ2E,OAAO,EAAEpB,YAAa;MAAAS,QAAA,EAAC;IAAgB;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACrD,CAAC;AAEV;AAAClE,EAAA,CA1IQD,GAAG;AAAA2E,EAAA,GAAH3E,GAAG;AA4IZ,eAAeA,GAAG;AAAC,IAAA2E,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}
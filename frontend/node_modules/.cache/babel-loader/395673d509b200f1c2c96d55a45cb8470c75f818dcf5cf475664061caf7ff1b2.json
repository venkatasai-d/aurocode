{"ast":null,"code":"var _jsxFileName = \"F:\\\\Kode\\\\Projects\\\\CGP_InterviewBot\\\\frontend\\\\src\\\\App.js\";\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { askLlama, storeInterview } from \"./api\"; // Import the API methods\n// import \"./App.css\"; // Import CSS for styling\n\n// function App() {\n//   const [name, setName] = useState(\"\");\n//   const [questions, setQuestions] = useState([]);\n//   const [currentQuestion, setCurrentQuestion] = useState(\"\");\n//   const [currentAnswer, setCurrentAnswer] = useState(\"\");\n//   const { transcript, resetTranscript, listening } = useSpeechRecognition(); // Include listening state\n//   const [llamaResponse, setLlamaResponse] = useState(\"\");\n\n//   // Function to fetch a question from the LLM (LLama) backend\n//   const fetchLlamaQuestion = async () => {\n//     try {\n//       const response = await askLlama(\"Ask me a question about programming\");\n//       setCurrentQuestion(response.data.question);\n//       setQuestions([...questions, response.data.question]);\n//       setLlamaResponse(response.data.question); // Corrected this line\n//     } catch (error) {\n//       console.error(\"Error fetching question from LLama:\", error);\n//       setLlamaResponse(\"Error: Unable to fetch question from LLama\");\n//     }\n//   };\n\n//   // Function to handle speech input\n//   const handleStartListening = () => {\n//     console.log(\"Starting to listen...\"); // Debugging line\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n\n//   const handleStopListening = () => {\n//     console.log(\"Stopping listening...\"); // Debugging line\n//     SpeechRecognition.stopListening();\n//     console.log(\"Transcript:\", transcript); // Debugging: Show the transcript\n//     setCurrentAnswer(transcript); // Set the current transcript as the answer\n//     resetTranscript();\n//   };\n\n//   // Function to submit the interview responses to the backend\n//   const handleSubmit = async () => {\n//     const interview = {\n//       interviewee_name: name,\n//       responses: questions.map((q) => ({ question: q, answer: currentAnswer })),\n//     };\n//     console.log(\"Submitting interview data:\", interview);\n//     try {\n//       await storeInterview(interview); // This will call the backend and store the interview\n//       alert(\"Interview submitted!\");\n//     } catch (error) {\n//       console.error(\"Error submitting the interview:\", error);\n//     }\n//   };\n\n//   return (\n//     <div className=\"App\">\n//       <h1>Interview Bot</h1>\n\n//       <input\n//         type=\"text\"\n//         placeholder=\"Enter your name\"\n//         value={name}\n//         onChange={(e) => setName(e.target.value)}\n//       />\n\n//       <button onClick={fetchLlamaQuestion}>Ask LLama</button>\n\n//       {llamaResponse && (\n//         <div>\n//           <h3>LLama Response:</h3>\n//           <p>{llamaResponse}</p>\n//         </div>\n//       )}\n\n//       <p>\n//         <strong>Question:</strong> {currentQuestion}\n//       </p>\n\n//       <button onClick={handleStartListening}>Start Answering</button>\n//       <button onClick={handleStopListening}>Stop Answering</button>\n\n//       <p>\n//         <strong>Your Answer:</strong> {transcript}{\" \"}\n//         {/* Show real-time transcript */}\n//       </p>\n\n//       <p>\n//         <strong>Listening:</strong> {listening ? \"Yes\" : \"No\"}{\" \"}\n//         {/* Display listening state */}\n//       </p>\n\n//       <button onClick={handleSubmit}>Submit Interview</button>\n//     </div>\n//   );\n// }\n\n// export default App;\nimport SpeechTest from \"./SpeechTest\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(SpeechTest, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 106,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 105,\n    columnNumber: 5\n  }, this);\n}\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["SpeechTest","jsxDEV","_jsxDEV","App","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["F:/Kode/Projects/CGP_InterviewBot/frontend/src/App.js"],"sourcesContent":["// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { askLlama, storeInterview } from \"./api\"; // Import the API methods\n// import \"./App.css\"; // Import CSS for styling\n\n// function App() {\n//   const [name, setName] = useState(\"\");\n//   const [questions, setQuestions] = useState([]);\n//   const [currentQuestion, setCurrentQuestion] = useState(\"\");\n//   const [currentAnswer, setCurrentAnswer] = useState(\"\");\n//   const { transcript, resetTranscript, listening } = useSpeechRecognition(); // Include listening state\n//   const [llamaResponse, setLlamaResponse] = useState(\"\");\n\n//   // Function to fetch a question from the LLM (LLama) backend\n//   const fetchLlamaQuestion = async () => {\n//     try {\n//       const response = await askLlama(\"Ask me a question about programming\");\n//       setCurrentQuestion(response.data.question);\n//       setQuestions([...questions, response.data.question]);\n//       setLlamaResponse(response.data.question); // Corrected this line\n//     } catch (error) {\n//       console.error(\"Error fetching question from LLama:\", error);\n//       setLlamaResponse(\"Error: Unable to fetch question from LLama\");\n//     }\n//   };\n\n//   // Function to handle speech input\n//   const handleStartListening = () => {\n//     console.log(\"Starting to listen...\"); // Debugging line\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n\n//   const handleStopListening = () => {\n//     console.log(\"Stopping listening...\"); // Debugging line\n//     SpeechRecognition.stopListening();\n//     console.log(\"Transcript:\", transcript); // Debugging: Show the transcript\n//     setCurrentAnswer(transcript); // Set the current transcript as the answer\n//     resetTranscript();\n//   };\n\n//   // Function to submit the interview responses to the backend\n//   const handleSubmit = async () => {\n//     const interview = {\n//       interviewee_name: name,\n//       responses: questions.map((q) => ({ question: q, answer: currentAnswer })),\n//     };\n//     console.log(\"Submitting interview data:\", interview);\n//     try {\n//       await storeInterview(interview); // This will call the backend and store the interview\n//       alert(\"Interview submitted!\");\n//     } catch (error) {\n//       console.error(\"Error submitting the interview:\", error);\n//     }\n//   };\n\n//   return (\n//     <div className=\"App\">\n//       <h1>Interview Bot</h1>\n\n//       <input\n//         type=\"text\"\n//         placeholder=\"Enter your name\"\n//         value={name}\n//         onChange={(e) => setName(e.target.value)}\n//       />\n\n//       <button onClick={fetchLlamaQuestion}>Ask LLama</button>\n\n//       {llamaResponse && (\n//         <div>\n//           <h3>LLama Response:</h3>\n//           <p>{llamaResponse}</p>\n//         </div>\n//       )}\n\n//       <p>\n//         <strong>Question:</strong> {currentQuestion}\n//       </p>\n\n//       <button onClick={handleStartListening}>Start Answering</button>\n//       <button onClick={handleStopListening}>Stop Answering</button>\n\n//       <p>\n//         <strong>Your Answer:</strong> {transcript}{\" \"}\n//         {/* Show real-time transcript */}\n//       </p>\n\n//       <p>\n//         <strong>Listening:</strong> {listening ? \"Yes\" : \"No\"}{\" \"}\n//         {/* Display listening state */}\n//       </p>\n\n//       <button onClick={handleSubmit}>Submit Interview</button>\n//     </div>\n//   );\n// }\n\n// export default App;\nimport SpeechTest from \"./SpeechTest\";\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <SpeechTest />\n    </div>\n  );\n}\n\nexport default App;\n"],"mappings":";AAAA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,OAAOA,UAAU,MAAM,cAAc;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtC,SAASC,GAAGA,CAAA,EAAG;EACb,oBACED,OAAA;IAAKE,SAAS,EAAC,KAAK;IAAAC,QAAA,eAClBH,OAAA,CAACF,UAAU;MAAAM,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACX,CAAC;AAEV;AAACC,EAAA,GANQP,GAAG;AAQZ,eAAeA,GAAG;AAAC,IAAAO,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}
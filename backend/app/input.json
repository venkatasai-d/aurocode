{ "model": "llama3", "prompt": "", "context": [], "stream": false }
